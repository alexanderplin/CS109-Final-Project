{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection and Filtering\n",
    "#### Angela Jiang, Alexander Lin, Jason Shen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Angela/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.linear_model import LogisticRegressionCV as LogRegCV\n",
    "import math\n",
    "import string \n",
    "from six.moves.html_parser import HTMLParser\n",
    "import urllib2\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=4, delay=3, backoff=2, logger=None):\n",
    "    \"\"\"Retry calling the decorated function using an exponential backoff.\n",
    "\n",
    "    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n",
    "    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "\n",
    "    :param ExceptionToCheck: the exception to check. may be a tuple of\n",
    "        exceptions to check\n",
    "    :type ExceptionToCheck: Exception or tuple\n",
    "    :param tries: number of times to try (not retry) before giving up\n",
    "    :type tries: int\n",
    "    :param delay: initial delay between retries in seconds\n",
    "    :type delay: int\n",
    "    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n",
    "        each retry\n",
    "    :type backoff: int\n",
    "    :param logger: logger to use. If None, print\n",
    "    :type logger: logging.Logger instance\n",
    "    \"\"\"\n",
    "    def deco_retry(f):\n",
    "\n",
    "        @wraps(f)\n",
    "        def f_retry(*args, **kwargs):\n",
    "            mtries, mdelay = tries, delay\n",
    "            while mtries > 1:\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                except ExceptionToCheck, e:\n",
    "                    msg = \"%s, Retrying in %d seconds...\" % (str(e), mdelay)\n",
    "                    if logger:\n",
    "                        logger.warning(msg)\n",
    "                    else:\n",
    "                        print msg\n",
    "                    time.sleep(mdelay)\n",
    "                    mtries -= 1\n",
    "                    mdelay *= backoff\n",
    "            return f(*args, **kwargs)\n",
    "\n",
    "        return f_retry  # true decorator\n",
    "\n",
    "    return deco_retry\n",
    "\n",
    "@retry(urllib2.HTTPError, tries=4, delay=3, backoff=2)\n",
    "def get_url_with_retry(url):\n",
    "    \"\"\" Makes API call to url and returns json response \"\"\"\n",
    "    response = urllib2.urlopen(url)\n",
    "    text = response.read()\n",
    "    test = json.loads(text)\n",
    "    response.close()\n",
    "    return test\n",
    "\n",
    "def make_url(year, month, api_key):\n",
    "    \"\"\" Returns string of API url to retrieve New York Times articles from the given year and month \"\"\"\n",
    "    return 'http://api.nytimes.com/svc/archive/v1/{}/{}.json?api-key={}'.format(year, month, api_key)\n",
    "\n",
    "def get_news_by_time(df, year, month, api_key):\n",
    "    \"\"\" Makes API call to retrive New York Times articles from the given year and month\n",
    "    df: pandas dataframe with columns 'headline', 'paragraph', 'pub_date'\n",
    "    Returns updated dataframe df with the 'headline', 'paragraph', 'pub_date' info\n",
    "    of the retrieved articles \"\"\"\n",
    "    df_index = df.shape[0]\n",
    "    \n",
    "    # set URL with parameters of year and month [earliest first]\n",
    "    url = make_url(year, month, api_key)\n",
    "    # initial API call\n",
    "    returned = get_url_with_retry(url)\n",
    "\n",
    "    # get num results\n",
    "    num_results = len(returned['response']['docs'])\n",
    "    print 'Number of total results for {}/{}: {}'.format(month, year, num_results)\n",
    "\n",
    "    articles_month_count = 0\n",
    "\n",
    "    # for each of the results of the month, add results to dataframe\n",
    "    for i, result in enumerate(returned['response']['docs']):\n",
    "        # only look at articles, not multimedia or blog posts\n",
    "        if type(result) is tuple:\n",
    "            print i, result\n",
    "            result = result[1]\n",
    "        if result['document_type'] == 'article':\n",
    "            if 'main' in result['headline']:\n",
    "                headline = result['headline']['main']\n",
    "            else:\n",
    "                headline = result['lead_paragraph']\n",
    "            df.loc[df_index] = [headline, result['lead_paragraph'], result['pub_date']]\n",
    "            df_index += 1\n",
    "            articles_month_count += 1\n",
    "\n",
    "    print 'Number of article results for {}/{}: {}'.format(month, year, articles_month_count)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates dataframe to store data from 10 years\n",
    "ten_year_data = pd.DataFrame(columns=('headline', 'paragraph', 'pub_date'))\n",
    "\n",
    "# stores constants\n",
    "api_key = 'd5a1e6fab7f04a10b2d3844b1b32b1ba'\n",
    "start_year = 2006\n",
    "start_month = 11\n",
    "end_year = 2016\n",
    "end_month = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total results for 2/2014: 7742\n",
      "Number of article results for 2/2014: 4767\n",
      "Number of total results for 3/2014: 8088\n",
      "Number of article results for 3/2014: 5345\n",
      "Number of total results for 4/2014: 7765\n",
      "Number of article results for 4/2014: 5168\n",
      "Number of total results for 5/2014: 8026\n",
      "Number of article results for 5/2014: 5525\n",
      "Number of total results for 6/2014: 8157\n",
      "Number of article results for 6/2014: 5389\n",
      "Number of total results for 7/2014: 7405\n",
      "Number of article results for 7/2014: 5022\n",
      "Number of total results for 8/2014: 7080\n",
      "Number of article results for 8/2014: 4858\n",
      "Number of total results for 9/2014: 8212\n",
      "Number of article results for 9/2014: 5162\n",
      "Number of total results for 10/2014: 8403\n",
      "Number of article results for 10/2014: 5437\n",
      "Number of total results for 11/2014: 7566\n",
      "Number of article results for 11/2014: 5223\n",
      "Number of total results for 12/2014: 7375\n",
      "Number of article results for 12/2014: 4934\n",
      "Number of total results for 1/2015: 7207\n",
      "Number of article results for 1/2015: 4870\n",
      "Number of total results for 2/2015: 6768\n",
      "Number of article results for 2/2015: 4477\n",
      "Number of total results for 3/2015: 7078\n",
      "Number of article results for 3/2015: 5116\n",
      "Number of total results for 4/2015: 7016\n",
      "Number of article results for 4/2015: 5070\n",
      "Number of total results for 5/2015: 7260\n",
      "Number of article results for 5/2015: 5366\n",
      "Number of total results for 6/2015: 7146\n",
      "Number of article results for 6/2015: 5058\n",
      "Number of total results for 7/2015: 7101\n",
      "Number of article results for 7/2015: 5049\n",
      "Number of total results for 8/2015: 6682\n",
      "Number of article results for 8/2015: 4764\n",
      "Number of total results for 9/2015: 7575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-439-a065db5d1cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mten_year_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_news_by_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mten_year_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd5a1e6fab7f04a10b2d3844b1b32b1ba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# to next month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-424-d4d310703124>\u001b[0m in \u001b[0;36mget_news_by_time\u001b[0;34m(df, year, month, api_key)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mheadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead_paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mheadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lead_paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pub_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mdf_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0marticles_month_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                        name=indexer)\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   4336\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4337\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 4338\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   4339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4340\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    844\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                        copy=copy)\n\u001b[0;32m--> 846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                                   \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m                                                   copy=self.copy)\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4543\u001b[0m                                                 copy=copy),\n\u001b[1;32m   4544\u001b[0m                          placement=placement)\n\u001b[0;32m-> 4545\u001b[0;31m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   4648\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4650\u001b[0;31m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4652\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Angela/anaconda2/lib/python2.7/site-packages/pandas/types/concat.pyc\u001b[0m in \u001b[0;36m_concat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculates number of calls (= number of months) that need to be made to the API function\n",
    "num_calls = (end_year - start_year)*12 + end_month  - start_month + 1\n",
    "year = start_year\n",
    "month = start_month\n",
    "\n",
    "# make API call for each year/month\n",
    "for call in range(num_calls):\n",
    "    ten_year_data = get_news_by_time(ten_year_data, year, month, api_key)\n",
    "    \n",
    "    # to next month\n",
    "    month += 1\n",
    "    \n",
    "    # reset month, update year if after december\n",
    "    if month == 13:\n",
    "        month = 1\n",
    "        year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_to_9_2015 = ten_year_data.reset_index(drop=True)\n",
    "data_to_9_2015.head(n=5)\n",
    "data_to_9_2015.to_excel('data_to_9_2015_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "* We did this data collection in batches because sometimes the API calls would time out, and we exported the dataframe from each batch to Excel (smaller file size than csvs). We then consolidated the batches of Excel documents into a single Excel document and saved it as '10_year_data.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total articles: 655600\n"
     ]
    }
   ],
   "source": [
    "# read in full article data over the past 10 years\n",
    "df = pd.read_excel('10_year_data.xlsx')\n",
    "df['pub_date'] = pd.DatetimeIndex(df['pub_date']).normalize()\n",
    "print 'Number of total articles:', df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_data(data, option = 'headline', date_filter = None, word_filter = None, pos = None, stem = False):\n",
    "    \"\"\" Helper function that filters data by dates and/or words\n",
    "    data = pandas dataframe with columns 'pub_date', 'headline', 'paragraph'\n",
    "    option = 'headline' or 'paragraph' (default = 'headline')\n",
    "    date_filer = (start date, end date) inclusive; else if default = None, then no filter \n",
    "    word_filter = list of words to filter OPTION by (CASE SENSITIVE); default is None\n",
    "    pos = list of parts of speech tags (default = None)\n",
    "    stem = boolean, whether or not to stem (default = False)\"\"\"\n",
    "    \n",
    "    h = HTMLParser()\n",
    "    \n",
    "    # filter by dates\n",
    "    if date_filter is not None:\n",
    "        start_date, end_date = date_filter\n",
    "        filtered_data = data[(data['publish_date'] >= start_date) & (data['publish_date'] <= end_date)]\n",
    "    else:\n",
    "        filtered_data = data\n",
    "        \n",
    "    # filter by words\n",
    "    if word_filter is not None:\n",
    "        idx_to_drop = [] # store indices of rows that do not contain filter words\n",
    "        \n",
    "        # for every article\n",
    "        for i in range(filtered_data.shape[0]):\n",
    "            text = filtered_data.iloc[i][option]\n",
    "            \n",
    "            # iterates through each filter word\n",
    "            filter_flag = 0\n",
    "            # if there is no text (type is not string)\n",
    "            if isinstance(text, basestring) is False:\n",
    "                idx_to_drop.append(i)\n",
    "                continue\n",
    "            for word in word_filter:\n",
    "                if word in text:\n",
    "                    filter_flag = 1\n",
    "                    break\n",
    "            # if no filter words in text, drop\n",
    "            if filter_flag == 0:\n",
    "                idx_to_drop.append(i)\n",
    "    \n",
    "    # drops rows without words in filter\n",
    "    filtered_data = filtered_data.drop(filtered_data.index[idx_to_drop])\n",
    "    \n",
    "    # remove caps\n",
    "    filtered_data[option] = filtered_data[option].str.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    # remove html encoding puncuation from old news\n",
    "    html_encoding = ['&#8217;', '&#8212;', '&#038;', '&#8230;', '&#8220;', '&#8221;']\n",
    "    for i in range(filtered_data.shape[0]):\n",
    "        for encoding in html_encoding:\n",
    "            if encoding in filtered_data.iloc[i][option]:\n",
    "                index = filtered_data.index[i]\n",
    "                filtered_data.loc[index, option] = filtered_data.loc[index, option].replace(encoding, h.unescape(encoding))\n",
    "    \n",
    "    # remove other punctuation\n",
    "    punctuation = list(',.!@#$%^&*()\\'\\\"`:;?' + u'\\u2018' + u'\\u2019')\n",
    "    for c in punctuation:\n",
    "        filtered_data[option] = filtered_data[option].str.replace(c, '')\n",
    "        \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles after filtering: 1430\n"
     ]
    }
   ],
   "source": [
    "# filter by Apple-related key words in the headlines\n",
    "filtered_df = filter_data(df, word_filter = ['Apple', 'AAPL', 'iPhone', 'iPod', 'MacBook'], option = 'headline')\n",
    "print 'Number of articles after filtering', filtered_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export to Excel\n",
    "filtered_df.to_excel('10_year_filtered_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
